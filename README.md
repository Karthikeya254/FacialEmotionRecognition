# Facial Emotion Recognition using various Deep Learning Architectures and Network Compression using Dark Knowledge
Facial Emotion Recognition (FER) plays a vital role in Monitoring systems, Entertainment, Consumer Marketing, Education, Health, etc. This project presents a comprehensive analysis of the FER performance of various Deep Learning network architectures like AlexNet, VGGNet, ResNet, CapsuleNet and an ensemble of AlexNet, VGGNet and ResNet. The task is to classify am image into one of the seven categories: Neutral, Happy, Sad, Surprise, Anger, Fear and Disgust. Convolutional autoencoders were developed to map each emotion to a latent space which were then used to classify examples based on distance proximity. Though the ensemble network yielded accuracies close to State-of the art, the memory and run-time requirements were intensive. This was minimized by compressing the ensemble network using it's Dark Knowledge without any deprecation in performance. The models were trained, validated and tested on 50K images from the Affectnet database. The performance of the models were compared in terms of the number of network parameters and accuracy. Ensemble network with dark knowledge gave the best accuracy of 62% with 91% reduction in parameters as compared to the parent ensemble network.

[Full Text of the Report](https://github.com/Karthikeya254/FacialEmotionRecognition/blob/master/paper.pdf)
